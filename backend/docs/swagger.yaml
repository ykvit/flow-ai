basePath: /api
definitions:
  flow-ai_backend_internal_llm.DeleteModelRequest:
    properties:
      name:
        example: mistral:7b
        type: string
    type: object
  flow-ai_backend_internal_llm.ListModelsResponse:
    properties:
      models:
        items:
          $ref: '#/definitions/flow-ai_backend_internal_llm.Model'
        type: array
    type: object
  flow-ai_backend_internal_llm.Model:
    properties:
      modified_at:
        type: string
      name:
        type: string
      size:
        type: integer
    type: object
  flow-ai_backend_internal_llm.ModelInfo:
    properties:
      modelfile:
        type: string
      parameters:
        type: string
      template:
        type: string
    type: object
  flow-ai_backend_internal_llm.PullModelRequest:
    properties:
      name:
        example: mistral:7b
        type: string
      stream:
        type: boolean
    type: object
  flow-ai_backend_internal_llm.PullStatus:
    properties:
      completed:
        type: integer
      digest:
        type: string
      error:
        type: string
      status:
        type: string
      total:
        type: integer
    type: object
  flow-ai_backend_internal_llm.RequestOptions:
    properties:
      repeat_penalty:
        example: 1.1
        type: number
      seed:
        example: 42
        type: integer
      system:
        example: You are a senior database administrator.
        type: string
      temperature:
        example: 0.7
        type: number
      top_k:
        example: 40
        type: integer
      top_p:
        example: 0.9
        type: number
    type: object
  flow-ai_backend_internal_llm.ShowModelRequest:
    properties:
      name:
        example: qwen3:8b
        type: string
    type: object
  flow-ai_backend_internal_model.Chat:
    properties:
      created_at:
        example: "2025-09-08T14:00:00Z"
        type: string
      id:
        example: 4b3b5a34-571f-47e3-abd1-a7dbee9d92fe
        type: string
      model:
        example: qwen:0.5b
        type: string
      title:
        example: History of the Roman Empire
        type: string
      updated_at:
        example: "2025-09-08T14:05:00Z"
        type: string
    type: object
  flow-ai_backend_internal_model.FullChat:
    properties:
      created_at:
        example: "2025-09-08T14:00:00Z"
        type: string
      id:
        example: 4b3b5a34-571f-47e3-abd1-a7dbee9d92fe
        type: string
      messages:
        items:
          $ref: '#/definitions/flow-ai_backend_internal_model.Message'
        type: array
      model:
        example: qwen:0.5b
        type: string
      title:
        example: History of the Roman Empire
        type: string
      updated_at:
        example: "2025-09-08T14:05:00Z"
        type: string
    type: object
  flow-ai_backend_internal_model.Message:
    properties:
      content:
        example: The Roman Empire fell in 476 AD.
        type: string
      id:
        example: a1b2c3d4-e5f6-7890-1234-567890abcdef
        type: string
      metadata:
        type: object
      model:
        example: qwen:0.5b
        type: string
      parent_id:
        example: f0e9d8c7-b6a5-4321-fedc-ba9876543210
        type: string
      role:
        example: assistant
        type: string
      timestamp:
        example: "2025-09-08T14:05:00Z"
        type: string
    type: object
  flow-ai_backend_internal_model.StreamResponse:
    properties:
      content:
        example: Hello
        type: string
      context:
        type: object
      done:
        example: false
        type: boolean
      error:
        type: string
    type: object
  flow-ai_backend_internal_service.CreateMessageRequest:
    properties:
      chat_id:
        example: 4b3b5a34-571f-47e3-abd1-a7dbee9d92fe
        type: string
      content:
        example: What is the difference between SQL and NoSQL databases?
        minLength: 1
        type: string
      model:
        example: qwen3:8b
        type: string
      options:
        $ref: '#/definitions/flow-ai_backend_internal_llm.RequestOptions'
      support_model:
        type: string
      system_prompt:
        type: string
    required:
    - content
    type: object
  flow-ai_backend_internal_service.RegenerateMessageRequest:
    properties:
      chat_id:
        description: Included for client-side context.
        type: string
      model:
        example: mistral:7b
        type: string
      options:
        allOf:
        - $ref: '#/definitions/flow-ai_backend_internal_llm.RequestOptions'
        description: Allows overriding generation parameters, e.g., for a more creative
          response.
      system_prompt:
        type: string
    type: object
  flow-ai_backend_internal_service.Settings:
    properties:
      main_model:
        description: The primary model for new chats. Must be an available local model.
        example: qwen3:8b
        type: string
      support_model:
        description: A model for background tasks like title generation. Can be the
          same as the main model.
        example: gemma3:4b
        type: string
      system_prompt:
        example: You are a helpful assistant that always answers in Markdown format.
        type: string
    required:
    - main_model
    type: object
  internal_api.ErrorResponse:
    properties:
      error:
        type: string
    type: object
  internal_api.StatusResponse:
    properties:
      status:
        type: string
    type: object
  internal_api.UpdateTitleRequest:
    properties:
      title:
        example: My Custom Chat Title
        maxLength: 100
        minLength: 1
        type: string
    required:
    - title
    type: object
info:
  contact:
    name: API Support
    url: https://github.com/ykvit/flow-ai/issues
  description: This is the API server for the Flow-AI application. It provides endpoints
    for managing chats, models, and application settings.
  license:
    name: MIT
    url: https://opensource.org/licenses/MIT
  title: Flow-AI API
  version: 0.0.1
paths:
  /v1/chats:
    get:
      description: Retrieves a list of all chats, sorted by the most recently updated.
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            items:
              $ref: '#/definitions/flow-ai_backend_internal_model.Chat'
            type: array
        "500":
          description: Internal Server Error
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
      summary: List all chats
      tags:
      - Chats
  /v1/chats/{chatID}:
    delete:
      description: Permanently deletes a chat and all its associated messages.
      parameters:
      - description: Chat ID
        in: path
        name: chatID
        required: true
        type: string
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/internal_api.StatusResponse'
        "404":
          description: Not Found
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
        "500":
          description: Internal Server Error
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
      summary: Delete a chat
      tags:
      - Chats
    get:
      description: Retrieves the full history for a single chat's active branch.
      parameters:
      - description: Chat ID
        in: path
        name: chatID
        required: true
        type: string
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/flow-ai_backend_internal_model.FullChat'
        "404":
          description: Not Found
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
      summary: Get a single chat
      tags:
      - Chats
  /v1/chats/{chatID}/messages/{messageID}/regenerate:
    post:
      consumes:
      - application/json
      description: |-
        Creates a new response for a previous user prompt.
        Creates a new response for a previous user prompt (SSE).
      parameters:
      - description: Chat ID
        in: path
        name: chatID
        required: true
        type: string
      - description: The ID of the assistant message to regenerate
        in: path
        name: messageID
        required: true
        type: string
      - description: Regeneration options
        in: body
        name: regenRequest
        required: true
        schema:
          $ref: '#/definitions/flow-ai_backend_internal_service.RegenerateMessageRequest'
      produces:
      - application/json
      responses:
        "200":
          description: Stream of new response chunks
          schema:
            $ref: '#/definitions/flow-ai_backend_internal_model.StreamResponse'
        "400":
          description: Sent as a stream error event
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
        "404":
          description: Sent as a stream error event
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
      summary: Regenerate a message
      tags:
      - Chats
  /v1/chats/{chatID}/title:
    put:
      consumes:
      - application/json
      description: Manually renames a chat.
      parameters:
      - description: Chat ID
        in: path
        name: chatID
        required: true
        type: string
      - description: New title
        in: body
        name: title
        required: true
        schema:
          $ref: '#/definitions/internal_api.UpdateTitleRequest'
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/internal_api.StatusResponse'
        "400":
          description: Bad Request
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
        "404":
          description: Not Found
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
        "500":
          description: Internal Server Error
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
      summary: Update a chat's title
      tags:
      - Chats
  /v1/chats/messages:
    post:
      consumes:
      - application/json
      description: |-
        Sends a new message and initiates a real-time stream of the assistant's response.
        Sends a new message and initiates a real-time stream of the assistant's response (SSE).
      parameters:
      - description: Message Request
        in: body
        name: message
        required: true
        schema:
          $ref: '#/definitions/flow-ai_backend_internal_service.CreateMessageRequest'
      produces:
      - application/json
      responses:
        "200":
          description: Stream of response chunks
          schema:
            $ref: '#/definitions/flow-ai_backend_internal_model.StreamResponse'
        "400":
          description: Sent as a stream error event
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
      summary: Create a message and stream the response
      tags:
      - Chats
  /v1/models:
    delete:
      consumes:
      - application/json
      description: Deletes a model from the local Ollama storage.
      parameters:
      - description: Model Name to Delete
        in: body
        name: modelRequest
        required: true
        schema:
          $ref: '#/definitions/flow-ai_backend_internal_llm.DeleteModelRequest'
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/internal_api.StatusResponse'
        "400":
          description: Bad Request
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
        "404":
          description: Not Found
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
        "500":
          description: Internal Server Error
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
      summary: Delete a local model
      tags:
      - Models
    get:
      description: Gets a list of all models available locally in Ollama.
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/flow-ai_backend_internal_llm.ListModelsResponse'
        "500":
          description: Internal Server Error
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
      summary: List local models
      tags:
      - Models
  /v1/models/pull:
    post:
      consumes:
      - application/json
      description: |-
        Downloads a model from the Ollama registry. This is a streaming endpoint.
        Downloads a model from the Ollama registry. This is a streaming endpoint (SSE).
      parameters:
      - description: Model Name to Pull
        in: body
        name: modelRequest
        required: true
        schema:
          $ref: '#/definitions/flow-ai_backend_internal_llm.PullModelRequest'
      produces:
      - application/json
      responses:
        "200":
          description: Stream of progress status
          schema:
            $ref: '#/definitions/flow-ai_backend_internal_llm.PullStatus'
        "400":
          description: Sent as a stream error event
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
      summary: Pull a new model
      tags:
      - Models
  /v1/models/show:
    post:
      consumes:
      - application/json
      description: Retrieves detailed information about a specific model.
      parameters:
      - description: Model Name
        in: body
        name: modelRequest
        required: true
        schema:
          $ref: '#/definitions/flow-ai_backend_internal_llm.ShowModelRequest'
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/flow-ai_backend_internal_llm.ModelInfo'
        "400":
          description: Bad Request
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
        "404":
          description: Not Found
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
      summary: Show model info
      tags:
      - Models
  /v1/settings:
    get:
      description: Retrieves the current global settings for the application.
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/flow-ai_backend_internal_service.Settings'
        "500":
          description: Internal Server Error
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
      summary: Get application settings
      tags:
      - Settings
    post:
      consumes:
      - application/json
      description: Updates the global settings. Models must be available in Ollama.
      parameters:
      - description: New settings to apply
        in: body
        name: settings
        required: true
        schema:
          $ref: '#/definitions/flow-ai_backend_internal_service.Settings'
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/internal_api.StatusResponse'
        "400":
          description: Bad Request
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
        "500":
          description: Internal Server Error
          schema:
            $ref: '#/definitions/internal_api.ErrorResponse'
      summary: Update application settings
      tags:
      - Settings
swagger: "2.0"
tags:
- description: Endpoints for creating, retrieving, and managing conversations.
  name: Chats
- description: Endpoints for listing, downloading, and managing local Ollama models.
  name: Models
- description: Endpoints for managing global application settings.
  name: Settings
