# Flow-AI Backend: Architecture and Design Decisions

This document outlines the architecture of the Flow-AI backend, explaining key design decisions and the overall workflow.

## 1. Core Philosophy

The backend is built on the principles of **Clean Architecture**. This means the code is organized into distinct layers, each with a specific responsibility. The primary benefit is a clear separation of concerns, which makes the system maintainable, testable, and scalable.

**The core rule is the Dependency Rule:** source code dependencies can only point inwards. The database knows nothing about the services, and the services know nothing about the API layer.

## 2. Layers of the Application

- **/cmd/server**: The application's entry point. Its only job is to initialize all components ("wiring") and start the HTTP server.
- **/internal/api**: The Presentation Layer (API). It handles HTTP requests, routing, and responses using `go-chi`. It uses versioned routes (e.g., `/api/v1`) and handlers are annotated with `swaggo` comments to auto-generate documentation.
- **/internal/service**: The Business Logic Layer. This is the heart of the application, orchestrating data flow and containing all business rules.
- **/internal/repository**: The Data Access Layer. It implements an interface for all database interactions with SQLite, abstracting the data source from the business logic.
- **/internal/database**: A utility package for initializing the database connection and migrating the schema.
- **/internal/config**: A package for managing configuration from environment variables and files.
- **/internal/llm**: The External Services Layer, abstracting all communication with the Ollama API.
- **/internal/model**: The Domain Layer, defining the core data structures (`Chat`, `Message`).
- **/docs**: This directory is **auto-generated by `swag`**. It contains the OpenAPI specification files. Do not edit its contents manually.

**Interactive Documentation:**
When the server is running, the interactive Swagger UI is accessible at `http://localhost:8000/api/swagger/index.html`.

## 3. Key Design Decisions

### Tree-like Message Structure
- **Decision:** The `messages` table uses `parent_id` and `is_active` columns.
- **Rationale:** This is the foundational decision that enables advanced features. It allows conversations to be stored as a tree, where each regeneration or edit creates a new branch. The `is_active` flag points to the currently visible timeline for the user.

### Database: SQLite over Redis
- **Decision:** We migrated the project from Redis to SQLite, running in **WAL (Write-Ahead Logging) mode**.
- **Rationale:** Simplicity of deployment (a single file), relational power for features like conversation branching, and excellent concurrent performance thanks to WAL mode.

### Dynamic & Self-Healing Model Configuration
- **Decision:** The application does not rely on hardcoded model names.
- **Rationale:** On first launch, the backend discovers available Ollama models, selects the most recent one as a default, and saves this configuration to the database. If the app starts with no models available, it will later "self-heal" its configuration once a model is pulled.

### Robust Startup Sequence
- **Decision:** The backend actively waits for the Ollama service to be ready before initializing.
- **Rationale:** This makes the application resilient to the unpredictable startup order in containerized environments like Docker Compose.

### Structured Title Generation
- **Decision:** The LLM is prompted to return chat titles in a strict JSON format.
- **Rationale:** This provides reliable, structured output. The backend includes "smart parsing" logic to extract this JSON even from noisy or conversational model responses.

### Auto-Generated API Documentation
- **Decision:** Use `swaggo/swag` to generate OpenAPI (Swagger) documentation from code comments.
- **Rationale:** This ensures the documentation is always synchronized with the code, provides an interactive UI for API testing, and serves as a single source of truth for the API contract.

## 4. DevOps and Quality Assurance

We adhere to modern DevOps practices to ensure code quality and reliability.

- **Automation with Makefile:** All development, testing, and deployment tasks are automated via a `Makefile`, providing a simple and consistent interface for all developers.
- **Reproducible Builds:** We use multi-stage Docker builds and pin specific versions of all tools (Go, `goimports`, `golangci-lint`) to ensure builds are identical regardless of where they are run.
- **Shift-Left Quality:** Code linting (`make lint`) and formatting (`make format`) are integral parts of the development workflow, catching issues early.
- **Isolated Integration Testing:** Our test suite (`make test`) runs in a completely isolated Docker environment with its own database and Ollama instance, ensuring tests are reliable and do not affect development data.